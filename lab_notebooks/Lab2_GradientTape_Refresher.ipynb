{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# âš™ï¸ Lab 2: TensorFlow GradientTape Refresher\n",
        "\n",
        "**Goal:** Recall how automatic differentiation and optimization loops work in TensorFlow.\n",
        "\n",
        "**Time:** ~10â€“15 minutes\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸš€ Exercise\n",
        "You'll:\n",
        "1. Create a simple scalar parameter `w` as a `tf.Variable`.\n",
        "2. Define a simple loss function, like mean squared error.\n",
        "3. Use `tf.GradientTape()` to compute gradients.\n",
        "4. Manually update `w` in a training loop.\n",
        "\n",
        "**Hint:** You can use `w.assign_sub(learning_rate * gradient)` to apply updates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Create a trainable variable\n",
        "\n",
        "**Goal:** Initialize a weight parameter that TensorFlow can optimize\n",
        "\n",
        "**Example Code:**\n",
        "```python\n",
        "w = tf.Variable(0.1, dtype=tf.float32, name='weight')\n",
        "print(f\"Initial w: {w.numpy()}\")\n",
        "```\n",
        "\n",
        "**Your Task:**\n",
        "- Create a `tf.Variable` named `w` with initial value 0.1\n",
        "- Print its value using `.numpy()`\n",
        "- Understand: Why use `tf.Variable` instead of a regular Python variable?\n",
        "\n",
        "**Key Concept:**\n",
        "- `tf.Variable` is mutable and tracked by TensorFlow for gradient computation\n",
        "- Start at 0.1 (not 0.0) to avoid edge cases\n",
        "\n",
        "**Documentation:**\n",
        "- tf.Variable: https://www.tensorflow.org/api_docs/python/tf/Variable\n",
        "- Variable guide: https://www.tensorflow.org/guide/variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create your trainable variable w here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Define inputs and true outputs\n",
        "\n",
        "**Goal:** Create training data for learning the relationship y = 3x\n",
        "\n",
        "**Example Code:**\n",
        "```python\n",
        "x_data = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0])\n",
        "y_true = tf.constant([3.0, 6.0, 9.0, 12.0, 15.0])\n",
        "print(f\"x: {x_data.numpy()}\")\n",
        "print(f\"y_true: {y_true.numpy()}\")\n",
        "```\n",
        "\n",
        "**Your Task:**\n",
        "- Create `x_data` and `y_true` as tf.constant tensors\n",
        "- Use the values above (the relationship is y = 3x)\n",
        "- Print both to verify\n",
        "\n",
        "**Key Concept:**\n",
        "- We're trying to learn that w â‰ˆ 3\n",
        "- Our model will be: y_pred = w * x\n",
        "- Through training, w should converge to 3.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Define x_data and y_true here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Define learning rate\n",
        "\n",
        "**Goal:** Set how fast the model learns\n",
        "\n",
        "**Example Code:**\n",
        "```python\n",
        "learning_rate = 0.01\n",
        "```\n",
        "\n",
        "**Your Task:**\n",
        "- Set `learning_rate = 0.01`\n",
        "- Understand: What happens if it's too large? Too small?\n",
        "\n",
        "**Key Concept:**\n",
        "- **Too large (>0.1)**: Training becomes unstable, loss might explode\n",
        "- **Too small (<0.001)**: Training is very slow\n",
        "- **0.01**: Good starting point for this simple problem\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Set your learning rate\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Use GradientTape in a training loop\n",
        "\n",
        "**Goal:** Implement gradient descent manually\n",
        "\n",
        "**Training Loop Structure:**\n",
        "```python\n",
        "num_epochs = 50\n",
        "loss_history = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Forward pass\n",
        "        y_pred = w * x_data\n",
        "        loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "    \n",
        "    # Backward pass\n",
        "    grad = tape.gradient(loss, w)\n",
        "    \n",
        "    # Update weight\n",
        "    w.assign_sub(learning_rate * grad)\n",
        "    \n",
        "    # Track progress\n",
        "    loss_history.append(loss.numpy())\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch + 1:3d}: w = {w.numpy():.4f}, loss = {loss.numpy():.6f}\")\n",
        "```\n",
        "\n",
        "**Your Task:**\n",
        "- Implement the training loop above\n",
        "- Print progress every 10 epochs\n",
        "- Print final w value (should be close to 3.0)\n",
        "\n",
        "**Key Operations:**\n",
        "- `tape.gradient(loss, w)`: Computes âˆ‚loss/âˆ‚w\n",
        "- `w.assign_sub(...)`: Updates w = w - learning_rate * gradient\n",
        "- Loss should decrease over epochs!\n",
        "\n",
        "**Documentation:**\n",
        "- GradientTape guide: https://www.tensorflow.org/guide/autodiff\n",
        "- GradientTape API: https://www.tensorflow.org/api_docs/python/tf/GradientTape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Implement your training loop with GradientTape\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5a: Plot loss curve\n",
        "\n",
        "**Plotting Code:**\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(loss_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.title('Training Loss with GradientTape')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Your Task:**\n",
        "- Plot the loss history\n",
        "- Observe: Does loss decrease smoothly? Any jumps?\n",
        "\n",
        "---\n",
        "\n",
        "### Step 5b: Test predictions\n",
        "\n",
        "**Testing Code:**\n",
        "```python\n",
        "test_x = tf.constant([6.0, 7.0, 8.0])\n",
        "test_pred = w * test_x\n",
        "print(\"\\nTest Predictions:\")\n",
        "for x_val, pred_val in zip(test_x.numpy(), test_pred.numpy()):\n",
        "    expected = 3.0 * x_val\n",
        "    print(f\"  x={x_val:.1f}: predicted={pred_val:.2f}, expected={expected:.2f}\")\n",
        "```\n",
        "\n",
        "**Your Task:**\n",
        "- Test on new x values: [6.0, 7.0, 8.0]\n",
        "- Compare predictions to expected (3x)\n",
        "- Verify your trained w works correctly!\n",
        "\n",
        "**Expected Results:**\n",
        "- For x=6: should predict ~18 (3Ã—6)\n",
        "- For x=7: should predict ~21 (3Ã—7)\n",
        "- For x=8: should predict ~24 (3Ã—8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Test your model on new x values\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
